# CityFlow Predictability & Demand Dashboard

CityFlow is an interactive dashboard that ties together three layers of your thesis:

1. **Individual-level mobility predictability** (sparsity `q`, theoretical upper bound `Πmax`, radius of gyration `Rg`, weekly regularity `R`)
2. **Next-POI recommendation benchmarks** on the Massive-STEPS dataset
3. **T5-based city-level demand forecasting**, with a lightweight LLM (Gemini) explainer

The app is built on top of the **[TailAdmin Free React Tailwind Admin Dashboard](https://tailadmin.com/)** template (`free-react-tailwind-admin-dashboard`) and customised into a thesis-specific “CityFlow” portal.

---

## 1. Features

### 1.1 Overview page

High-level landing page that summarises the whole thesis:

- **Key metrics card** – short explanations of `q`, `Πmax`, `Rg`, `R`, and Acc@1.
- **Three summary cards**
  - *Mobility Predictability*: 15 cities, median Πmax and qualitative variation.
  - *POI Recommendation Benchmarks*: Acc@1 range across classic models.
  - *T5 Demand Forecast*: 3 cities × 3 categories and the main findings.
- **Cross-city predictability snapshot**
  - Small selector for a representative city (Sydney/Tokyo/Jakarta/Bandung).
  - Text showing mean Πmax, share of high-Πmax users, and a short profile.
- **Model performance snapshot**
  - Selector for NYC/Sydney/Tokyo/Moscow.
  - Compares mean Πmax with Acc@1 of STHGCN and a T5/LLM-Move-style model.

All cards link into the detailed pages.

---

### 1.2 Mobility Predictability page

**Route:** `/mobility-predictability`

Interactive explorer for city-level mobility metrics (15 Massive-STEPS cities):

- **City selector** for all 15 cities.
- **Metric definition card** explaining:
  - `q` – sparsity / missing rate.
  - `Πmax` – entropy-based theoretical upper bound on next-POI accuracy.
  - `Rg (km)` – radius of gyration (spatial dispersion).
  - `R` – weekly regularity (hours-of-week concentration).
- **Metric cards** (per selected city):
  - Median `q`
  - Mean `Πmax`
  - Median `Rg` (km)
  - Median `R`
  - Plus counts: total users, valid users, share of high-Πmax users, etc.
- **Radar chart**
  - Plots the four key metrics for **all 15 cities** in a single view.
  - Tabbed UI allows you to compare the selected city with other profiles.
- **City mobility profile**
  - Short textual description mapping the city into one of the three qualitative profiles from the thesis
    - “Local & regular”
    - “More dispersed & mixed regularity”
    - “Small / unstable sample”

All numbers are taken directly from the thesis tables.

---

### 1.3 POI Benchmarks page

**Route:** `/poi-benchmarks`

Visualisation of next-POI model benchmarks (Acc@1):

- **Models covered**
  - FPMC, RNN, LSTPM, DeepMove, GETNext, STHGCN, UniMove
- **15-city × model Acc@1 table**
  - Reproduced from the official Massive-STEPS benchmark.
- **City-wise bar chart**
  - For a selected city, shows Acc@1 of all models side by side.
- **STHGCN vs. Πmax utilisation curve**
  - For each city, plots `Acc@1(STHGCN) / Πmax(mean)` to visualise how close the best classic model gets to the theoretical upper bound.
- **Narrative card**
  - Explains how model performance interacts with Πmax and data sparsity.

Again, this page intentionally mirrors exactly what is in the thesis (no new “mystery” metrics).

---

### 1.4 T5 Forecast (chat) page

**Route:** `/t5-forecast`

Chat-style interface that talks to your FastAPI backend and T5 models.

- **Controls**
  - City selector: `New York City`, `Sydney`, `Moscow`
  - Category selector: `Bar`, `Coffee Shop`, `Metro Station` (or “all”)
  - Model selector:
    - `Baseline` (city-level model, always used when no category is picked)
    - `Category fine-tune` (only enabled when city + category are both set)
- **Chat interface**
  - User writes a natural language query like  
    `“Forecast bar demand in Sydney on Friday 8pm.”`
  - Messages are sent to `/t5-chat` with the full history + controls.
  - Response shows:
    - The discrete T5 demand bucket (from your trained model)
    - A short explanation generated by Gemini (rendered with Markdown).

The LLM explainer is prompted to:

- Treat the **T5 prediction as fixed** (never change the number/bucket).
- Explain the result in simple business language for a non-technical store owner.
- Optionally refer to high-level concepts (regularity, zero-heavy demand, cross-city transfer difficulty) without inventing new numeric metrics.

---

## 2. Tech Stack

### Frontend

- **React 18 + TypeScript**
- **Tailwind CSS** (from TailAdmin template)
- **React Router** for navigation
- **ApexCharts (react-apexcharts)** for charts (bar, radar, line)
- **react-markdown** to render Gemini’s explanation in Markdown
- Dark-mode support inherited from TailAdmin

### Backend

- **FastAPI** (Python)
- **Uvicorn** for local dev server
- **transformers / Hugging Face Hub**
  - T5-small sequence-to-sequence models
  - Baseline city-level model + category-specific fine-tuned variants
- **google-generativeai**
  - Gemini API as a lightweight explanation layer
- **python-dotenv**
  - Automatically loads `api/.env` for HF and Gemini keys

---

## 3. Project Structure (simplified)

```text
free-react-tailwind-admin-dashboard/
├─ public/
│  └─ images/logo/        # Re-branded CityFlow SVG logos
├─ src/
│  ├─ components/
│  │  └─ common/PageMeta.tsx
│  ├─ pages/
│  │  ├─ Dashboard/Home.tsx            # Overview page
│  │  ├─ MobilityPredictability.tsx    # City mobility metrics
│  │  ├─ POIBenchmarks.tsx             # POI benchmark visualisation
│  │  └─ T5Forecast.tsx                # Chat-style T5 forecast UI
│  └─ ...
└─ api/
   ├─ main.py               # FastAPI app, loads .env and registers routers
   ├─ routes/
   │  ├─ manifest.py        # Simple “what models exist” manifest (from earlier)
   │  ├─ forecast.py        # Core T5 forecasting logic + /forecast endpoint
   │  ├─ t5_chat.py         # /t5-chat endpoint (chat wrapper around T5)
   │  └─ llm_explainer.py   # Gemini-based explanation helper
   └─ .env                  # Backend env vars (HF + Gemini)
````

---

## 4. Environment variables

### 4.1 Frontend (`.env` at project root)

```bash
# Optional: override if backend isn't on localhost:8000
VITE_API_BASE_URL=http://127.0.0.1:8000
```

### 4.2 Backend (`api/.env`)

```bash
# Hugging Face
HF_TOKEN=...                 # Access token for private repos
HF_HOME=.hf_cache
HF_HUB_CACHE=.hf_cache

# Gemini / Google Generative AI
GOOGLE_API_KEY=...           # API key from Google AI Studio
```

> **Important:** never commit real tokens or API keys to Git.

The backend loads `api/.env` automatically in `api/main.py` via `python-dotenv`.

---

## 5. Running the project locally

### 5.1 Install dependencies

```bash
# 1. Install frontend dependencies
npm install

# 2. Create a virtualenv for the backend (optional but recommended)
cd api
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install Python dependencies
pip install -r requirements.txt
# If you don't have a requirements file, minimally:
# pip install fastapi uvicorn transformers huggingface_hub python-dotenv google-generativeai
```

Create and fill in **`api/.env`** as described above.

### 5.2 Run backend (FastAPI)

From the project root (or inside `api/`):

```bash
cd api
uvicorn api.main:app --reload --port 8000
```

You should see logs for:

* HF self-check (preloading the baseline T5 model)
* Gemini setup (if `GOOGLE_API_KEY` is present)

Quick health check:

```bash
curl http://127.0.0.1:8000/ping
# => {"msg":"pong"}
```

### 5.3 Run frontend (Vite dev server)

In another terminal, from the project root:

```bash
npm run dev
```

Then open the URL printed in the console (usually `http://localhost:5173/`).

---

## 6. Deployment notes

* **Frontend:** can be deployed to Vercel / Netlify / any static hosting, built with:

  ```bash
  npm run build
  npm run preview   # optional local preview
  ```
* **Backend:** can be deployed to Render, Railway, or any service that supports a FastAPI app.

  * Remember to set:

    * `HF_TOKEN`, `HF_HOME`, `HF_HUB_CACHE`
    * `GOOGLE_API_KEY`
  * Update `VITE_API_BASE_URL` in the frontend build environment to point at the deployed API URL.

---

## 7. Acknowledgements

* UI template based on **TailAdmin – Free React Tailwind Admin Dashboard**.
* Mobility metrics and benchmark numbers from the **Massive-STEPS** dataset and your thesis analysis.
* T5 demand forecasting model adapted from your PromptCast / T5 sequence-to-sequence setup.
* LLM explanations powered by **Google Gemini** (via `google-generativeai`).

This README is intentionally written so someone else (e.g. supervisor or examiner) can clone the repo, set a few environment variables, and understand how each dashboard page corresponds to sections in your thesis.
